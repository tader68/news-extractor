from flask import Flask, render_template, request, jsonify
import requests
from bs4 import BeautifulSoup
import re
import urllib3
import ssl
from urllib3.util.ssl_ import create_urllib3_context
import urllib.request
import urllib.parse
import google.generativeai as genai
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time

# Táº¯t cáº£nh bÃ¡o SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

app = Flask(__name__)

# Cáº¥u hÃ¬nh Gemini API
import os
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY', 'AIzaSyBNU2IteZpqb93aISVU38Z0fN9r_Wc3_qs')
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

def extract_with_selenium(url):
    """
    Sá»­ dá»¥ng Selenium Ä‘á»ƒ trÃ­ch xuáº¥t tiÃªu Ä‘á» vÃ  ná»™i dung tá»« URL
    """
    try:
        # Cáº¥u hÃ¬nh Chrome options cho production (Render.com compatible)
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # Cháº¡y áº©n
        chrome_options.add_argument('--no-sandbox')  # Critical for cloud deployment
        chrome_options.add_argument('--disable-dev-shm-usage')  # Critical for cloud deployment
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--ignore-certificate-errors')
        chrome_options.add_argument('--ignore-ssl-errors')
        chrome_options.add_argument('--ignore-certificate-errors-spki-list')
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--allow-running-insecure-content')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-images')  # Faster loading
        # chrome_options.add_argument('--disable-javascript')  # Keep JS enabled for some sites
        chrome_options.add_argument('--disable-background-timer-throttling')
        chrome_options.add_argument('--disable-backgrounding-occluded-windows')
        chrome_options.add_argument('--disable-renderer-backgrounding')
        chrome_options.add_argument('--disable-features=TranslateUI')
        chrome_options.add_argument('--disable-ipc-flooding-protection')
        chrome_options.add_argument('--remote-debugging-port=9222')  # For cloud debugging
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # Cloud-specific optimizations
        chrome_options.add_argument('--single-process')  # Use single process for cloud
        chrome_options.add_argument('--disable-background-networking')
        chrome_options.add_argument('--disable-default-apps')
        chrome_options.add_argument('--disable-sync')
        chrome_options.add_argument('--metrics-recording-only')
        chrome_options.add_argument('--no-first-run')
        chrome_options.add_argument('--safebrowsing-disable-auto-update')
        chrome_options.add_argument('--disable-logging')
        chrome_options.add_argument('--disable-notifications')
        
        # Force Selenium for problematic domains
        force_selenium_domains = ['bnews.vn', 'baotintuc.vn', 'vietnamnet.vn']
        if any(domain in url for domain in force_selenium_domains):
            print(f"ğŸ”„ Force using Selenium for domain: {url}")
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # Táº¡o driver
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        print(f"Sá»­ dá»¥ng Selenium cho URL: {url}")
        driver.get(url)
        
        # Äá»£i trang load
        time.sleep(3)
        
        # Láº¥y HTML content
        html_content = driver.page_source
        driver.quit()
        
        # Parse vá»›i BeautifulSoup
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # TÃ¬m tiÃªu Ä‘á»
        title = None
        title_selectors = [
            'h1.title', 'h1.detail-title', 'h1.article-title', 'h1.post-title',
            '.title', '.detail-title', '.article-title', '.post-title', 
            'h1', '.entry-title', 'title'
        ]
        
        for selector in title_selectors:
            title_element = soup.select_one(selector)
            if title_element:
                title_text = title_element.get_text().strip()
                if title_text and len(title_text) > 5:  # Chá»‰ láº¥y náº¿u cÃ³ ná»™i dung thá»±c sá»±
                    title = title_text
                    break
        
        # TÃ¬m ná»™i dung
        content_text = None
        
        # Xá»­ lÃ½ Ä‘áº·c biá»‡t cho vietnamnet.vn
        if 'vietnamnet.vn' in url:
            print("ğŸ” Xá»­ lÃ½ Ä‘áº·c biá»‡t cho vietnamnet.vn trong Selenium...")
            
            # TÃ¬m sapo tá»« tháº» h2
            sapo_selectors = [
                'h2[class="content-detail-sapo sm-sapo-mb-0"]',
                'h2.content-detail-sapo',
                'h2[class*="content-detail-sapo"]',
                'h2[class*="sapo"]',
                '.content-detail-sapo',
                '[class*="sapo"]'
            ]
            
            for selector in sapo_selectors:
                print(f"ğŸ” Selenium thá»­ selector: {selector}")
                sapo_element = soup.select_one(selector)
                if sapo_element:
                    sapo_text = sapo_element.get_text().strip()
                    print(f"ğŸ“ Selenium tÃ¬m tháº¥y sapo: {sapo_text}")
                    
                    if len(sapo_text) > 30 and not sapo_text.endswith('...'):
                        content_text = sapo_text
                        print(f"âœ… Selenium láº¥y sapo thÃ nh cÃ´ng!")
                        break
                    else:
                        print(f"âŒ Selenium sapo khÃ´ng há»£p lá»‡ (ngáº¯n hoáº·c cÃ³ ...)")
                else:
                    print(f"âŒ Selenium khÃ´ng tÃ¬m tháº¥y element vá»›i selector {selector}")
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y sapo, thá»­ tÃ¬m táº¥t cáº£ tháº» h2
            if not content_text:
                print("ğŸ” Selenium tÃ¬m táº¥t cáº£ tháº» h2...")
                all_h2 = soup.find_all('h2')
                for i, h2 in enumerate(all_h2):
                    h2_classes = h2.get('class', [])
                    h2_text = h2.get_text().strip()
                    print(f"Selenium H2 {i+1}: classes={h2_classes}, text='{h2_text[:100]}...'")
                    
                    if 'sapo' in ' '.join(h2_classes).lower() and len(h2_text) > 30 and not h2_text.endswith('...'):
                        print(f"âœ… Selenium tÃ¬m tháº¥y sapo tá»« tháº» h2 thá»© {i+1}")
                        content_text = h2_text
                        break
        
        # Xá»­ lÃ½ Ä‘áº·c biá»‡t cho baotintuc.vn
        elif 'baotintuc.vn' in url:
            print("ğŸ” Xá»­ lÃ½ Ä‘áº·c biá»‡t cho baotintuc.vn trong Selenium...")
            
            # Æ¯u tiÃªn tÃ¬m sapo trÆ°á»›c
            sapo_selectors = [
                'h2.sapo',
                'h2[class="sapo"]',
                '.sapo'
            ]
            
            for selector in sapo_selectors:
                print(f"ğŸ” Selenium thá»­ sapo selector: {selector}")
                sapo_element = soup.select_one(selector)
                if sapo_element:
                    sapo_text = sapo_element.get_text().strip()
                    print(f"ğŸ“ Selenium tÃ¬m tháº¥y sapo baotintuc: {sapo_text}")
                    
                    if len(sapo_text) > 50:
                        content_text = sapo_text
                        print(f"âœ… Selenium láº¥y sapo baotintuc thÃ nh cÃ´ng: {len(sapo_text.split())} tá»«")
                        break
                else:
                    print(f"âŒ Selenium khÃ´ng tÃ¬m tháº¥y sapo vá»›i selector {selector}")
            
                        # Náº¿u khÃ´ng tÃ¬m tháº¥y sapo, fallback vá» logic thÃ´ng thÆ°á»ng
            pass
        
        # Náº¿u khÃ´ng pháº£i vietnamnet/baotintuc hoáº·c khÃ´ng tÃ¬m tháº¥y ná»™i dung Ä‘áº·c biá»‡t, thá»­ meta description
        if not content_text:
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            if meta_desc and meta_desc.get('content'):
                desc = meta_desc.get('content').strip()
                if len(desc) > 50:
                    content_text = desc
        
        # Náº¿u khÃ´ng cÃ³ meta description, tÃ¬m trong tháº» p
        if not content_text:
            paragraphs = soup.find_all('p')
            for p in paragraphs:
                text = p.get_text().strip()
                if (len(text) > 80 and 
                    not any(keyword in text.lower() for keyword in [
                        'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                        'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement'
                    ])):
                    content_text = text
                    break
        
        # Náº¿u ná»™i dung chÆ°a Ä‘á»§ 80 tá»«, láº¥y thÃªm Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
        if content_text:
            content_words = len(content_text.split())
            
            # Kiá»ƒm tra xem cÃ³ pháº£i lÃ  vietnamnet vÃ  Ä‘Ã£ láº¥y tá»« sapo khÃ´ng
            is_vietnamnet_sapo = 'vietnamnet.vn' in url and any(selector in str(soup) for selector in ['content-detail-sapo', 'sapo'])
            
            if content_words < 80 and not is_vietnamnet_sapo:
                print(f"Selenium: Ná»™i dung hiá»‡n táº¡i cÃ³ {content_words} tá»«, chÆ°a Ä‘á»§ 80 tá»«. Äang láº¥y thÃªm Ä‘oáº¡n vÄƒn káº¿ tiáº¿p...")
                
                # TÃ¬m Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
                paragraphs = soup.find_all('p')
                for i, p in enumerate(paragraphs):
                    text = p.get_text().strip()
                    if (len(text) > 50 and 
                        not any(keyword in text.lower() for keyword in [
                            'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                            'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement'
                        ])):
                        
                        # Kiá»ƒm tra xem Ä‘oáº¡n nÃ y cÃ³ khÃ¡c vá»›i Ä‘oáº¡n Ä‘Ã£ láº¥y khÃ´ng
                        if text != content_text:
                            # Káº¿t há»£p Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
                            combined_content = content_text + " " + text
                            combined_words = len(combined_content.split())
                            
                            print(f"Selenium: ÄÃ£ káº¿t há»£p Ä‘oáº¡n vÄƒn káº¿ tiáº¿p. Tá»•ng tá»«: {combined_words}")
                            content_text = combined_content
                            
                            # Náº¿u Ä‘Ã£ Ä‘á»§ 80 tá»«, dá»«ng láº¡i
                            if combined_words >= 80:
                                break
            elif is_vietnamnet_sapo:
                print(f"âœ… Selenium: ÄÃ£ láº¥y tá»« sapo vietnamnet, khÃ´ng cáº§n káº¿t há»£p thÃªm. Sá»‘ tá»«: {content_words}")
        
        if title and content_text:
            return {
                "title": title,
                "content": content_text,
                "success": True
            }
        else:
            return {
                "title": "KhÃ´ng tÃ¬m tháº¥y tiÃªu Ä‘á»",
                "content": "KhÃ´ng tÃ¬m tháº¥y ná»™i dung",
                "success": False
            }
        
    except Exception as e:
        print(f"Lá»—i Selenium: {str(e)}")
        return {
            "title": "Lá»—i Selenium",
            "content": f"KhÃ´ng thá»ƒ sá»­ dá»¥ng Selenium: {str(e)}",
            "success": False
        }

def extract_with_gemini(url):
    """
    Sá»­ dá»¥ng Gemini API Ä‘á»ƒ trÃ­ch xuáº¥t tiÃªu Ä‘á» vÃ  ná»™i dung tá»« URL
    """
    try:
        # Sá»­ dá»¥ng URL Context tool Ä‘á»ƒ truy cáº­p trá»±c tiáº¿p URL
        try:
            # Táº¡o prompt vá»›i URL context tool
            prompt = f"""
            Truy cáº­p URL nÃ y vÃ  Ä‘á»c chÃ­nh xÃ¡c ná»™i dung: {url}
            
            HÃ£y trÃ­ch xuáº¥t:
            1. TiÃªu Ä‘á» chÃ­nh cá»§a bÃ i bÃ¡o (tá»« tháº» h1 hoáº·c title)
            2. Äoáº¡n vÄƒn Ä‘áº§u tiÃªn cá»§a bÃ i bÃ¡o (Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn trong ná»™i dung chÃ­nh)
            
            Tráº£ vá» theo format chÃ­nh xÃ¡c:
            TiÃªu Ä‘á»: [tiÃªu Ä‘á» chÃ­nh xÃ¡c tá»« trang web]
            Ná»™i dung: [Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn chÃ­nh xÃ¡c tá»« trang web]
            
            QUAN TRá»ŒNG: Äá»c ká»¹ vÃ  trÃ­ch xuáº¥t chÃ­nh xÃ¡c tá»« trang web, khÃ´ng tá»± suy Ä‘oÃ¡n hay tÃ³m táº¯t.
            """
            
            # Sá»­ dá»¥ng prompt Ä‘Æ¡n giáº£n (URL context tool khÃ´ng hoáº¡t Ä‘á»™ng)
            response = model.generate_content(prompt)
            result_text = response.text.strip()
            
            # Debug: In ra response Ä‘á»ƒ kiá»ƒm tra
            print(f"Gemini response for {url}:")
            print(result_text)
            print("=" * 50)
            
            # Loáº¡i bá» code Python náº¿u cÃ³
            if '```python' in result_text:
                result_text = result_text.split('```python')[0]
            if '```' in result_text:
                result_text = result_text.split('```')[0]
            
            # Náº¿u response cÃ³ váº» há»£p lÃ½, sá»­ dá»¥ng nÃ³
            if len(result_text) > 50 and not any(keyword in result_text.lower() for keyword in ['python', 'import', 'def ', 'function', 'requests.get', 'beautifulsoup']):
                # TÃ¡ch tiÃªu Ä‘á» vÃ  ná»™i dung tá»« response
                lines = result_text.split('\n')
                title = ""
                content = ""
                
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith('URL:'):
                        # LÃ m sáº¡ch format
                        cleaned_line = line
                        
                        # Loáº¡i bá» sá»‘ thá»© tá»± vÃ  dáº¥u **
                        if cleaned_line.startswith('1. '):
                            cleaned_line = cleaned_line[3:]
                        if cleaned_line.startswith('2. '):
                            cleaned_line = cleaned_line[3:]
                        
                        # Loáº¡i bá» dáº¥u **
                        cleaned_line = cleaned_line.replace('**', '').strip()
                        
                        # Loáº¡i bá» pháº§n mÃ´ táº£
                        if 'TiÃªu Ä‘á» bÃ i bÃ¡o lÃ :' in cleaned_line:
                            cleaned_line = cleaned_line.replace('TiÃªu Ä‘á» bÃ i bÃ¡o lÃ :', '').strip()
                        if 'Ná»™i dung Ä‘oáº¡n Ä‘áº§u tiÃªn cá»§a bÃ i bÃ¡o lÃ :' in cleaned_line:
                            cleaned_line = cleaned_line.replace('Ná»™i dung Ä‘oáº¡n Ä‘áº§u tiÃªn cá»§a bÃ i bÃ¡o lÃ :', '').strip()
                        if 'TiÃªu Ä‘á»:' in cleaned_line:
                            cleaned_line = cleaned_line.replace('TiÃªu Ä‘á»:', '').strip()
                        if 'Ná»™i dung:' in cleaned_line:
                            cleaned_line = cleaned_line.replace('Ná»™i dung:', '').strip()
                        
                        if not title and cleaned_line:
                            title = cleaned_line
                        elif not content and cleaned_line:
                            content = cleaned_line
                            break
                
                if title and content:
                    return {
                        "title": title,
                        "content": content,
                        "success": True
                    }
                
                # Náº¿u khÃ´ng tÃ¡ch Ä‘Æ°á»£c theo cÃ¡ch trÃªn, thá»­ cÃ¡ch khÃ¡c
                # TÃ¬m "TiÃªu Ä‘á»:" vÃ  "Ná»™i dung:" trong response
                if 'TiÃªu Ä‘á»:' in result_text and 'Ná»™i dung:' in result_text:
                    try:
                        title_start = result_text.find('TiÃªu Ä‘á»:') + 8
                        content_start = result_text.find('Ná»™i dung:')
                        title_end = content_start
                        
                        title = result_text[title_start:title_end].strip()
                        content = result_text[content_start + 8:].strip()
                        
                        # LÃ m sáº¡ch thÃªm
                        title = title.replace('**', '').strip()
                        content = content.replace('**', '').strip()
                        
                        if title and content:
                            return {
                                "title": title,
                                "content": content,
                                "success": True
                            }
                    except:
                        pass
        except:
            pass
        
        # Náº¿u prompt Ä‘Æ¡n giáº£n khÃ´ng hoáº¡t Ä‘á»™ng, thá»­ prompt chi tiáº¿t
        prompt = f"""
        Truy cáº­p URL nÃ y vÃ  trÃ­ch xuáº¥t chÃ­nh xÃ¡c:
        {url}
        
        Tráº£ vá» theo format chÃ­nh xÃ¡c:
        TiÃªu Ä‘á»: [tiÃªu Ä‘á» chÃ­nh xÃ¡c tá»« trang web]
        Ná»™i dung: [Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn chÃ­nh xÃ¡c tá»« trang web]
        
        KHÃ”NG thÃªm pháº§n mÃ´ táº£, chá»‰ tráº£ vá» ná»™i dung thá»±c táº¿.
        """
        
        response = model.generate_content(prompt)
        result_text = response.text.strip()
        
        # Xá»­ lÃ½ response tá»« prompt chi tiáº¿t
        import json
        
        # LÃ m sáº¡ch response
        cleaned_text = result_text
        
        # Loáº¡i bá» cÃ¡c Ä‘oáº¡n code Python
        if '```python' in cleaned_text:
            cleaned_text = cleaned_text.split('```python')[0]
        if '```' in cleaned_text:
            cleaned_text = cleaned_text.split('```')[0]
        
        # Loáº¡i bá» cÃ¡c tá»« khÃ³a khÃ´ng cáº§n thiáº¿t
        unwanted_phrases = [
            'import requests', 'from bs4 import BeautifulSoup', 'def extract_',
            'try:', 'except:', 'return {', 'headers = {', 'response = requests.get',
            'soup = BeautifulSoup', 'title_element = soup.select_one'
        ]
        
        for phrase in unwanted_phrases:
            if phrase in cleaned_text:
                cleaned_text = cleaned_text.split(phrase)[0]
        
        # Thá»­ tÃ¡ch tiÃªu Ä‘á» vÃ  ná»™i dung tá»« text
        lines = cleaned_text.split('\n')
        title = ""
        content = ""
        
        for line in lines:
            line = line.strip()
            if line:
                # LÃ m sáº¡ch format
                cleaned_line = line
                
                # Loáº¡i bá» sá»‘ thá»© tá»± vÃ  dáº¥u **
                if cleaned_line.startswith('1. '):
                    cleaned_line = cleaned_line[3:]
                if cleaned_line.startswith('2. '):
                    cleaned_line = cleaned_line[3:]
                
                # Loáº¡i bá» dáº¥u **
                cleaned_line = cleaned_line.replace('**', '').strip()
                
                # Loáº¡i bá» pháº§n mÃ´ táº£
                if 'TiÃªu Ä‘á» bÃ i bÃ¡o lÃ :' in cleaned_line:
                    cleaned_line = cleaned_line.replace('TiÃªu Ä‘á» bÃ i bÃ¡o lÃ :', '').strip()
                if 'Ná»™i dung Ä‘oáº¡n Ä‘áº§u tiÃªn cá»§a bÃ i bÃ¡o lÃ :' in cleaned_line:
                    cleaned_line = cleaned_line.replace('Ná»™i dung Ä‘oáº¡n Ä‘áº§u tiÃªn cá»§a bÃ i bÃ¡o lÃ :', '').strip()
                if 'TiÃªu Ä‘á»:' in cleaned_line:
                    cleaned_line = cleaned_line.replace('TiÃªu Ä‘á»:', '').strip()
                if 'Ná»™i dung:' in cleaned_line:
                    cleaned_line = cleaned_line.replace('Ná»™i dung:', '').strip()
                
                if not title and cleaned_line:
                    title = cleaned_line
                elif not content and cleaned_line:
                    content = cleaned_line
                    break
        
        if title and content:
            return {
                "title": title,
                "content": content,
                "success": True
            }
        
        # Náº¿u khÃ´ng tÃ¡ch Ä‘Æ°á»£c, tráº£ vá» text Ä‘Ã£ lÃ m sáº¡ch
        return {
            "title": "TiÃªu Ä‘á» tá»« Gemini",
            "content": cleaned_text[:300] + "..." if len(cleaned_text) > 300 else cleaned_text,
            "success": True
        }
            
    except Exception as e:
        return {
            "title": "Lá»—i Gemini API",
            "content": f"KhÃ´ng thá»ƒ sá»­ dá»¥ng Gemini API: {str(e)}",
            "success": False
        }

def extract_title_and_content(url):
    """
    TrÃ­ch xuáº¥t tiÃªu Ä‘á» vÃ  Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn tá»« URL bÃ i bÃ¡o
    """
    try:
        # Force Selenium for known problematic domains
        force_selenium_domains = ['bnews.vn', 'baotintuc.vn', 'vietnamnet.vn']
        if any(domain in url for domain in force_selenium_domains):
            print(f"ğŸš€ Using Selenium directly for {url}")
            return extract_with_selenium(url)
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'vi-VN,vi;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        # Thá»­ nhiá»u cÃ¡ch Ä‘á»ƒ truy cáº­p URL
        response = None
        
        # CÃ¡ch 1: Thá»­ vá»›i verify=False vÃ  session
        try:
            session = requests.Session()
            response = session.get(url, headers=headers, timeout=20, verify=False)
            response.raise_for_status()
        except requests.exceptions.SSLError as ssl_error:
            # CÃ¡ch 2: Thá»­ vá»›i urllib3 context tÃ¹y chá»‰nh
            try:
                import urllib3
                from urllib3.util.ssl_ import create_urllib3_context
                
                # Táº¡o context vá»›i cÃ i Ä‘áº·t SSL lá»ng láº»o
                ctx = create_urllib3_context()
                ctx.check_hostname = False
                ctx.verify_mode = ssl.CERT_NONE
                
                # Táº¡o session vá»›i context tÃ¹y chá»‰nh
                session = requests.Session()
                adapter = requests.adapters.HTTPAdapter()
                session.mount('https://', adapter)
                
                response = session.get(url, headers=headers, timeout=20, verify=False)
                response.raise_for_status()
                
            except requests.exceptions.SSLError:
                # CÃ¡ch 3: Thá»­ vá»›i HTTP thay vÃ¬ HTTPS
                if url.startswith('https://'):
                    http_url = url.replace('https://', 'http://')
                    try:
                        response = requests.get(http_url, headers=headers, timeout=20)
                        response.raise_for_status()
                    except Exception as e:
                        # CÃ¡ch 4: Thá»­ vá»›i urllib thay vÃ¬ requests
                        try:
                            # Táº¡o SSL context cho urllib
                            ssl_context = ssl.create_default_context()
                            ssl_context.check_hostname = False
                            ssl_context.verify_mode = ssl.CERT_NONE
                            
                            # Táº¡o request vá»›i urllib
                            req = urllib.request.Request(url, headers=headers)
                            with urllib.request.urlopen(req, context=ssl_context, timeout=20) as response_urllib:
                                content = response_urllib.read()
                                
                            # Táº¡o response object giáº£ Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i code cÅ©
                            class MockResponse:
                                def __init__(self, content):
                                    self.content = content
                                    self.status_code = 200
                                
                                def raise_for_status(self):
                                    pass
                            
                            response = MockResponse(content)
                            
                        except Exception as urllib_error:
                            # CÃ¡ch 5: Sá»­ dá»¥ng Selenium khi táº¥t cáº£ cÃ¡c cÃ¡ch khÃ¡c tháº¥t báº¡i
                            print(f"Sá»­ dá»¥ng Selenium cho URL: {url}")
                            selenium_result = extract_with_selenium(url)
                            
                            if selenium_result['success']:
                                # Táº¡o response object giáº£ tá»« káº¿t quáº£ Selenium
                                class MockResponse:
                                    def __init__(self, title, content):
                                        self.title = title
                                        self.content = content
                                        self.status_code = 200
                                    
                                    def raise_for_status(self):
                                        pass
                                
                                response = MockResponse(selenium_result['title'], selenium_result['content'])
                            else:
                                # CÃ¡ch 6: Sá»­ dá»¥ng Gemini API lÃ m fallback cuá»‘i cÃ¹ng
                                print(f"Sá»­ dá»¥ng Gemini API cho URL: {url}")
                                gemini_result = extract_with_gemini(url)
                                
                                if gemini_result['success']:
                                    class MockResponse:
                                        def __init__(self, title, content):
                                            self.title = title
                                            self.content = content
                                            self.status_code = 200
                                        
                                        def raise_for_status(self):
                                            pass
                                    
                                    response = MockResponse(gemini_result['title'], gemini_result['content'])
                                else:
                                    raise requests.exceptions.SSLError(f"KhÃ´ng thá»ƒ truy cáº­p URL do váº¥n Ä‘á» SSL vÃ  táº¥t cáº£ phÆ°Æ¡ng phÃ¡p Ä‘á»u tháº¥t báº¡i: {str(urllib_error)}")
                else:
                    raise requests.exceptions.SSLError(f"KhÃ´ng thá»ƒ truy cáº­p URL do váº¥n Ä‘á» SSL: {str(ssl_error)}")
        except Exception as e:
            raise requests.exceptions.RequestException(f"Lá»—i khi truy cáº­p URL: {str(e)}")
        
        # Kiá»ƒm tra xem response cÃ³ pháº£i tá»« Gemini API khÃ´ng
        if hasattr(response, 'title') and hasattr(response, 'content'):
            # Response tá»« Gemini API
            title = response.title
            content = response.content
            
            # Äáº¿m sá»‘ tá»«
            title_words = len(title.split()) if title else 0
            content_words = len(content.split()) if content else 0
            total_words = title_words + content_words
            
            return {
                'title': title,
                'content': content,
                'word_count': {
                    'title_words': title_words,
                    'content_words': content_words,
                    'total_words': total_words,
                    'meets_minimum': total_words >= 80
                },
                'success': True,
                'source': 'gemini_api'
            }
        
        # Response tá»« web scraping thÃ´ng thÆ°á»ng
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # TÃ¬m tiÃªu Ä‘á»
        title = None
        
        # Xá»­ lÃ½ Ä‘áº·c biá»‡t cho tienphong.vn
        if 'tienphong.vn' in url:
            print("ğŸ” Xá»­ lÃ½ Ä‘áº·c biá»‡t cho tienphong.vn...")
            tienphong_title_selectors = [
                'h1[class*="title"]',
                'h1.article-title',
                '.article-title h1',
                'h1',
                '.title'
            ]
            
            for selector in tienphong_title_selectors:
                print(f"ğŸ” Thá»­ title selector tienphong: {selector}")
                title_element = soup.select_one(selector)
                if title_element:
                    title_text = title_element.get_text().strip()
                    print(f"ğŸ“ TÃ¬m tháº¥y title: {title_text}")
                    if title_text and len(title_text) > 10:  # TiÃªu Ä‘á» pháº£i dÃ i hÆ¡n 10 kÃ½ tá»±
                        title = title_text
                        print(f"âœ… Láº¥y title thÃ nh cÃ´ng tá»« {selector}")
                        break
                else:
                    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y title vá»›i selector {selector}")
        
        # Náº¿u khÃ´ng pháº£i tienphong hoáº·c khÃ´ng tÃ¬m tháº¥y title, dÃ¹ng selector thÃ´ng thÆ°á»ng
        if not title:
            title_selectors = [
                'h1.title', 'h1.detail-title', 'h1.article-title', 'h1.post-title',
                '.title', '.detail-title', '.article-title', '.post-title', 
                'h1', '.entry-title', '[class*="title"]', '[class*="headline"]', 'title'
            ]
            
            for selector in title_selectors:
                title_element = soup.select_one(selector)
                if title_element:
                    title_text = title_element.get_text().strip()
                    if title_text and len(title_text) > 5:  # Chá»‰ láº¥y náº¿u cÃ³ ná»™i dung thá»±c sá»±
                        title = title_text
                        break
        
        # TÃ¬m Ä‘oáº¡n vÄƒn chÃ­nh cá»§a bÃ i bÃ¡o
        content = None
        
        # Xá»­ lÃ½ Ä‘áº·c biá»‡t cho vietnamnet.vn NGAY Tá»ª Äáº¦U
        if 'vietnamnet.vn' in url:
            print("ğŸ” Äang xá»­ lÃ½ vietnamnet.vn vá»›i web scraping thÃ´ng thÆ°á»ng...")
            print(f"URL: {url}")
            print("=== Báº®T Äáº¦U Xá»¬ LÃ VIETNAMNET.VN ===")
            
            # Æ¯u tiÃªn láº¥y tá»« tháº» h2.sapo (tÃ³m táº¯t bÃ i bÃ¡o) trÆ°á»›c
            sapo_selectors = [
                'h2[class="content-detail-sapo sm-sapo-mb-0"]',
                'h2.content-detail-sapo',
                'h2[class*="content-detail-sapo"]',
                'h2[class*="sapo"]',
                '.content-detail-sapo',
                '[class*="sapo"]'
            ]
            
            for selector in sapo_selectors:
                print(f"ğŸ” Äang thá»­ selector: {selector}")
                sapo_element = soup.select_one(selector)
                if sapo_element:
                    sapo_text = sapo_element.get_text().strip()
                    print(f"ğŸ“ TÃ¬m tháº¥y element vá»›i selector {selector}")
                    print(f"Ná»™i dung sapo (Ä‘áº§y Ä‘á»§): {sapo_text}")
                    print(f"Sá»‘ tá»« sapo: {len(sapo_text.split())}")
                    print(f"Äá»™ dÃ i kÃ½ tá»± sapo: {len(sapo_text)}")
                    
                    if len(sapo_text) > 30:
                        # Kiá»ƒm tra xem sapo cÃ³ bá»‹ cáº¯t ngáº¯n khÃ´ng
                        if sapo_text.endswith('...'):
                            print("âš ï¸ Cáº£nh bÃ¡o: Sapo bá»‹ cáº¯t ngáº¯n (káº¿t thÃºc báº±ng ...), bá» qua vÃ  tÃ¬m ná»™i dung Ä‘áº§y Ä‘á»§")
                            continue  # Bá» qua sapo bá»‹ cáº¯t ngáº¯n
                        
                        content = sapo_text
                        print(f"âœ… ÄÃ£ láº¥y sapo thÃ nh cÃ´ng tá»« selector {selector}, khÃ´ng káº¿t há»£p thÃªm Ä‘oáº¡n vÄƒn khÃ¡c")
                        break
                    else:
                        print(f"âŒ Sapo quÃ¡ ngáº¯n ({len(sapo_text)} kÃ½ tá»±), bá» qua")
                else:
                    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y element vá»›i selector {selector}")
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y sapo báº±ng selector, thá»­ tÃ¬m táº¥t cáº£ tháº» h2
            if not content:
                print("ğŸ” KhÃ´ng tÃ¬m tháº¥y sapo báº±ng selector, Ä‘ang tÃ¬m táº¥t cáº£ tháº» h2...")
                all_h2 = soup.find_all('h2')
                for i, h2 in enumerate(all_h2):
                    h2_classes = h2.get('class', [])
                    h2_text = h2.get_text().strip()
                    print(f"H2 {i+1}: classes={h2_classes}, text='{h2_text[:100]}...'")
                    
                    if 'sapo' in ' '.join(h2_classes).lower() and len(h2_text) > 30 and not h2_text.endswith('...'):
                        print(f"âœ… TÃ¬m tháº¥y sapo tá»« tháº» h2 thá»© {i+1}")
                        print(f"Ná»™i dung sapo (Ä‘áº§y Ä‘á»§): {h2_text}")
                        content = h2_text
                        break
            
            print(f"=== Káº¾T THÃšC Xá»¬ LÃ VIETNAMNET.VN - Káº¿t quáº£: {'ThÃ nh cÃ´ng' if content else 'Tháº¥t báº¡i'} ===")
        
        # Xá»­ lÃ½ Ä‘áº·c biá»‡t cho tienphong.vn
        elif 'tienphong.vn' in url:
            print("ğŸ” Äang xá»­ lÃ½ tienphong.vn...")
            print(f"URL: {url}")
            print("=== Báº®T Äáº¦U Xá»¬ LÃ TIENPHONG.VN ===")
            
            # TÃ¬m sapo cá»§a tienphong.vn
            tienphong_selectors = [
                'div.sapo p',
                '.article-sapo',
                '.content-sapo',
                'div[class*="sapo"]',
                '.lead'
            ]
            
            for selector in tienphong_selectors:
                print(f"ğŸ” Äang thá»­ selector: {selector}")
                sapo_element = soup.select_one(selector)
                if sapo_element:
                    sapo_text = sapo_element.get_text().strip()
                    print(f"ğŸ“ TÃ¬m tháº¥y element vá»›i selector {selector}")
                    print(f"Ná»™i dung sapo: {sapo_text}")
                    
                    if len(sapo_text) > 30:
                        content = sapo_text
                        print(f"âœ… ÄÃ£ láº¥y sapo thÃ nh cÃ´ng tá»« selector {selector}")
                        break
                else:
                    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y element vá»›i selector {selector}")
            
            print(f"=== Káº¾T THÃšC Xá»¬ LÃ TIENPHONG.VN - Káº¿t quáº£: {'ThÃ nh cÃ´ng' if content else 'Tháº¥t báº¡i'} ===")
        
        # Náº¿u khÃ´ng pháº£i vietnamnet/tienphong hoáº·c khÃ´ng tÃ¬m tháº¥y ná»™i dung Ä‘áº·c biá»‡t, Æ°u tiÃªn láº¥y tá»« meta description vÃ  káº¿t há»£p vá»›i Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn
        if not content:
            meta_description = soup.find('meta', attrs={'name': 'description'})
            if meta_description and meta_description.get('content'):
                desc_content = meta_description.get('content').strip()
                if len(desc_content) > 50:
                    # TÃ¬m Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn trong ná»™i dung Ä‘á»ƒ bá»• sung
                    first_paragraph = None
                
                # Thá»­ cÃ¡c selector cá»¥ thá»ƒ trÆ°á»›c
                content_selectors = [
                    'div.detail p', 'div.content p', 'article p', 
                    'div[class*="content"] p', 'div[class*="article"] p'
                ]
                
                for selector in content_selectors:
                    paragraphs = soup.select(selector)
                    if paragraphs:
                        for p in paragraphs:
                            text = p.get_text().strip()
                            if (len(text) > 80 and 
                                not any(keyword in text.lower() for keyword in [
                                    'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                                    'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement'
                                ])):
                                first_paragraph = text
                                break
                        if first_paragraph:
                            break
                
                # Náº¿u khÃ´ng tÃ¬m tháº¥y, tÃ¬m trong táº¥t cáº£ tháº» p
                if not first_paragraph:
                    all_paragraphs = soup.find_all('p')
                    for p in all_paragraphs:
                        text = p.get_text().strip()
                        if (len(text) > 80 and 
                            not any(keyword in text.lower() for keyword in [
                                'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                                'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement'
                            ])):
                            first_paragraph = text
                            break
                
                # Káº¿t há»£p meta description vá»›i Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn
                if first_paragraph and not first_paragraph.startswith(desc_content):
                    # Chá»‰ káº¿t há»£p meta description vá»›i Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn
                    content = desc_content + " " + first_paragraph
                else:
                    content = desc_content
                
                # Náº¿u ná»™i dung chÆ°a Ä‘á»§ 80 tá»«, láº¥y thÃªm Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
                if content:
                    content_words = len(content.split())
                    if content_words < 80:
                        print(f"Ná»™i dung hiá»‡n táº¡i cÃ³ {content_words} tá»«, chÆ°a Ä‘á»§ 80 tá»«. Äang láº¥y thÃªm Ä‘oáº¡n vÄƒn káº¿ tiáº¿p...")
                        
                        # TÃ¬m Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
                        all_paragraphs = soup.find_all('p')
                        for i, p in enumerate(all_paragraphs):
                            text = p.get_text().strip()
                            if (len(text) > 50 and 
                                not any(keyword in text.lower() for keyword in [
                                    'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                                    'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement'
                                ])):
                                
                                # Kiá»ƒm tra xem Ä‘oáº¡n nÃ y cÃ³ khÃ¡c vá»›i Ä‘oáº¡n Ä‘Ã£ láº¥y khÃ´ng
                                if text != content:
                                    # Káº¿t há»£p Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
                                    combined_content = content + " " + text
                                    combined_words = len(combined_content.split())
                                    
                                    print(f"ÄÃ£ káº¿t há»£p Ä‘oáº¡n vÄƒn káº¿ tiáº¿p. Tá»•ng tá»«: {combined_words}")
                                    print(f"Ná»™i dung káº¿t há»£p Ä‘áº§y Ä‘á»§: {combined_content}")
                                    content = combined_content
                                    
                                    # Náº¿u Ä‘Ã£ Ä‘á»§ 80 tá»«, dá»«ng láº¡i
                                    if combined_words >= 80:
                                        break
        
        # Logic vietnamnet.vn Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ á»Ÿ trÃªn
            print("Äang xá»­ lÃ½ vietnamnet.vn vá»›i web scraping thÃ´ng thÆ°á»ng...")
            print(f"URL: {url}")
            print("=== Báº®T Äáº¦U Xá»¬ LÃ VIETNAMNET.VN ===")
            
            # Æ¯u tiÃªn láº¥y tá»« tháº» h2.sapo (tÃ³m táº¯t bÃ i bÃ¡o) trÆ°á»›c
            sapo_selectors = [
                'h2[class="content-detail-sapo sm-sapo-mb-0"]',
                'h2.content-detail-sapo',
                'h2[class*="content-detail-sapo"]',
                'h2[class*="sapo"]',
                '.content-detail-sapo',
                '[class*="sapo"]'
            ]
            
            for selector in sapo_selectors:
                print(f"ğŸ” Äang thá»­ selector: {selector}")
                sapo_element = soup.select_one(selector)
                if sapo_element:
                    sapo_text = sapo_element.get_text().strip()
                    print(f"ğŸ“ TÃ¬m tháº¥y element vá»›i selector {selector}")
                    print(f"Ná»™i dung sapo (Ä‘áº§y Ä‘á»§): {sapo_text}")
                    print(f"Sá»‘ tá»« sapo: {len(sapo_text.split())}")
                    print(f"Äá»™ dÃ i kÃ½ tá»± sapo: {len(sapo_text)}")
                    
                    if len(sapo_text) > 30:
                        # Kiá»ƒm tra xem sapo cÃ³ bá»‹ cáº¯t ngáº¯n khÃ´ng
                        if sapo_text.endswith('...'):
                            print("âš ï¸ Cáº£nh bÃ¡o: Sapo bá»‹ cáº¯t ngáº¯n (káº¿t thÃºc báº±ng ...), bá» qua vÃ  tÃ¬m ná»™i dung Ä‘áº§y Ä‘á»§")
                            continue  # Bá» qua sapo bá»‹ cáº¯t ngáº¯n
                        
                        content = sapo_text
                        print(f"âœ… ÄÃ£ láº¥y sapo thÃ nh cÃ´ng tá»« selector {selector}, khÃ´ng káº¿t há»£p thÃªm Ä‘oáº¡n vÄƒn khÃ¡c")
                        break
                    else:
                        print(f"âŒ Sapo quÃ¡ ngáº¯n ({len(sapo_text)} kÃ½ tá»±), bá» qua")
                else:
                    print(f"âŒ KhÃ´ng tÃ¬m tháº¥y element vá»›i selector {selector}")
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y sapo báº±ng selector, thá»­ tÃ¬m táº¥t cáº£ tháº» h2
            if not content:
                print("ğŸ” KhÃ´ng tÃ¬m tháº¥y sapo báº±ng selector, Ä‘ang tÃ¬m táº¥t cáº£ tháº» h2...")
                all_h2 = soup.find_all('h2')
                for i, h2 in enumerate(all_h2):
                    h2_classes = h2.get('class', [])
                    h2_text = h2.get_text().strip()
                    print(f"H2 {i+1}: classes={h2_classes}, text='{h2_text[:100]}...'")
                    
                    if 'sapo' in ' '.join(h2_classes).lower() and len(h2_text) > 30:
                        print(f"âœ… TÃ¬m tháº¥y sapo tá»« tháº» h2 thá»© {i+1}")
                        print(f"Ná»™i dung sapo (Ä‘áº§y Ä‘á»§): {h2_text}")
                        content = h2_text
                        break
            
            # Äá»‹nh nghÄ©a content_selectors Ä‘á»ƒ dÃ¹ng cho cáº£ sapo vÃ  Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
            content_selectors = [
                'div[class*="content"] p',
                'article p',
                'div.detail p',
                'div.content p'
            ]
            
            # Náº¿u khÃ´ng tÃ¬m tháº¥y sapo hoáº·c sapo bá»‹ cáº¯t ngáº¯n, tÃ¬m Ä‘oáº¡n vÄƒn chÃ­nh tá»« vietnamnet.vn
            if not content:
                print("KhÃ´ng tÃ¬m tháº¥y sapo Ä‘áº§y Ä‘á»§, Ä‘ang tÃ¬m Ä‘oáº¡n vÄƒn chÃ­nh...")
            
                for selector in content_selectors:
                    paragraphs = soup.select(selector)
                    if paragraphs:
                        print(f"TÃ¬m tháº¥y {len(paragraphs)} Ä‘oáº¡n vÄƒn vá»›i selector: {selector}")
                        
                        # TÃ¬m Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn cÃ³ ná»™i dung thá»±c sá»±
                        first_valid_paragraph = None
                        for i, p in enumerate(paragraphs):
                            text = p.get_text().strip()
                            print(f"Äoáº¡n vÄƒn {i+1}: {text}")
                            
                        # Kiá»ƒm tra xem cÃ³ pháº£i Ä‘oáº¡n vÄƒn cÃ³ ná»™i dung thá»±c sá»± khÃ´ng
                        if (len(text) > 30 and  # Giáº£m yÃªu cáº§u Ä‘á»™ dÃ i
                            not any(keyword in text.lower() for keyword in [
                                'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                                'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement'
                            ]) and
                            not text.endswith('...') and  # KhÃ´ng láº¥y Ä‘oáº¡n bá»‹ cáº¯t
                            len(text.split()) > 5):  # Giáº£m yÃªu cáº§u sá»‘ tá»«
                            
                            # Æ¯u tiÃªn Ä‘oáº¡n vÄƒn cÃ³ ná»™i dung dÃ i hÆ¡n vÃ  khÃ´ng pháº£i tÃªn tÃ¡c giáº£
                            if (len(text) > 50 and 
                                not any(author in text.lower() for author in ['tháº¡ch tháº£o', 'má»¹ anh']) and
                                len(text.split()) > 10 and
                                not text.endswith('...')):  # KhÃ´ng láº¥y Ä‘oáº¡n vÄƒn bá»‹ cáº¯t ngáº¯n
                                print(f"âœ… TÃ¬m tháº¥y Ä‘oáº¡n vÄƒn Æ°u tiÃªn (Ä‘áº§y Ä‘á»§):")
                                print(f"Ná»™i dung Ä‘áº§y Ä‘á»§: {text}")
                                if not content:  # Chá»‰ gÃ¡n náº¿u chÆ°a cÃ³ content
                                    content = text
                                break
                            elif not first_valid_paragraph:
                                # LÆ°u Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn há»£p lá»‡ lÃ m backup
                                first_valid_paragraph = text
                                print(f"ğŸ“ LÆ°u Ä‘oáº¡n vÄƒn backup:")
                                print(f"Ná»™i dung Ä‘áº§y Ä‘á»§: {text}")
                        
                        # Náº¿u khÃ´ng tÃ¬m tháº¥y Ä‘oáº¡n vÄƒn Æ°u tiÃªn, dÃ¹ng Ä‘oáº¡n backup
                        if not content and first_valid_paragraph:
                            print(f"âœ… Sá»­ dá»¥ng Ä‘oáº¡n vÄƒn backup:")
                            print(f"Ná»™i dung Ä‘áº§y Ä‘á»§: {first_valid_paragraph}")
                            if not content:  # Chá»‰ gÃ¡n náº¿u chÆ°a cÃ³ content
                                content = first_valid_paragraph
                        
                        if content:
                            break
            
            # Náº¿u váº«n chÆ°a cÃ³ ná»™i dung, thá»­ cÃ¡ch khÃ¡c vá»›i logic nháº¥t quÃ¡n
            if not content:
                print("KhÃ´ng tÃ¬m tháº¥y ná»™i dung vá»›i selector Æ°u tiÃªn, thá»­ cÃ¡ch khÃ¡c...")
                # TÃ¬m trong táº¥t cáº£ tháº» p vá»›i logic nháº¥t quÃ¡n
                all_paragraphs = soup.find_all('p')
                first_valid_backup = None
                
                for p in all_paragraphs:
                    text = p.get_text().strip()
                    
                    # Kiá»ƒm tra Ä‘oáº¡n vÄƒn há»£p lá»‡
                    if (len(text) > 30 and 
                        not any(keyword in text.lower() for keyword in [
                            'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                            'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement'
                        ]) and
                        len(text.split()) > 5):
                        
                        # Æ¯u tiÃªn Ä‘oáº¡n vÄƒn dÃ i vÃ  khÃ´ng pháº£i tÃªn tÃ¡c giáº£
                        if (len(text) > 50 and 
                            not any(author in text.lower() for author in ['tháº¡ch tháº£o', 'má»¹ anh']) and
                            len(text.split()) > 10 and
                            not text.endswith('...')):  # KhÃ´ng láº¥y Ä‘oáº¡n vÄƒn bá»‹ cáº¯t ngáº¯n
                            print(f"âœ… TÃ¬m tháº¥y Ä‘oáº¡n vÄƒn Æ°u tiÃªn tá»« táº¥t cáº£ tháº» p (Ä‘áº§y Ä‘á»§):")
                            print(f"Ná»™i dung Ä‘áº§y Ä‘á»§: {text}")
                            if not content:  # Chá»‰ gÃ¡n náº¿u chÆ°a cÃ³ content
                                content = text
                            break
                        elif not first_valid_backup:
                            # LÆ°u Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn há»£p lá»‡ lÃ m backup
                            first_valid_backup = text
                            print(f"ğŸ“ LÆ°u Ä‘oáº¡n vÄƒn backup tá»« táº¥t cáº£ tháº» p:")
                            print(f"Ná»™i dung Ä‘áº§y Ä‘á»§: {text}")
                
                # Náº¿u khÃ´ng tÃ¬m tháº¥y Ä‘oáº¡n Æ°u tiÃªn, dÃ¹ng backup
                if not content and first_valid_backup:
                    print(f"âœ… Sá»­ dá»¥ng Ä‘oáº¡n vÄƒn backup tá»« táº¥t cáº£ tháº» p:")
                    print(f"Ná»™i dung Ä‘áº§y Ä‘á»§: {first_valid_backup}")
                    if not content:  # Chá»‰ gÃ¡n náº¿u chÆ°a cÃ³ content
                        content = first_valid_backup
            
            # Kiá»ƒm tra xem cÃ³ láº¥y tá»« sapo khÃ´ng
            sapo_found = False
            if content:
                for selector in sapo_selectors:
                    sapo_element = soup.select_one(selector)
                    if sapo_element:
                        sapo_text = sapo_element.get_text().strip()
                        if sapo_text == content:
                            sapo_found = True
                            print(f"âœ… XÃ¡c nháº­n Ä‘Ã£ láº¥y tá»« sapo: {sapo_text[:50]}...")
                            break
            
            # Náº¿u ná»™i dung vietnamnet.vn chÆ°a Ä‘á»§ 80 tá»«, láº¥y thÃªm Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
            # NHÆ¯NG chá»‰ khi KHÃ”NG láº¥y tá»« sapo
            if content and not sapo_found:
                content_words = len(content.split())
                if content_words < 80:
                    print(f"Ná»™i dung hiá»‡n táº¡i cÃ³ {content_words} tá»«, chÆ°a Ä‘á»§ 80 tá»«. Äang láº¥y thÃªm Ä‘oáº¡n vÄƒn káº¿ tiáº¿p...")
                    
                    # TÃ¬m Ä‘oáº¡n vÄƒn káº¿ tiáº¿p tá»« vietnamnet.vn
                    for selector in content_selectors:
                        paragraphs = soup.select(selector)
                        if paragraphs:
                            for p in paragraphs:
                                text = p.get_text().strip()
                                if (len(text) > 50 and 
                                    not any(keyword in text.lower() for keyword in [
                                        'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                                        'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement',
                                        'tháº¡ch tháº£o', 'má»¹ anh'
                                    ]) and
                                    text != content and  # KhÃ¡c vá»›i Ä‘oáº¡n Ä‘Ã£ láº¥y
                                    len(text.split()) > 10):
                                    
                                    # Káº¿t há»£p Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
                                    combined_content = content + " " + text
                                    combined_words = len(combined_content.split())
                                    
                                    print(f"ÄÃ£ káº¿t há»£p Ä‘oáº¡n vÄƒn káº¿ tiáº¿p. Tá»•ng tá»«: {combined_words}")
                                    print(f"Ná»™i dung káº¿t há»£p Ä‘áº§y Ä‘á»§: {combined_content}")
                                    content = combined_content
                                    
                                    # Náº¿u Ä‘Ã£ Ä‘á»§ 80 tá»«, dá»«ng láº¡i
                                    if combined_words >= 80:
                                        break
                            
                            if len(content.split()) >= 80:
                                break
            elif content and sapo_found:
                content_words = len(content.split())
                print(f"âœ… ÄÃ£ láº¥y tá»« sapo, khÃ´ng káº¿t há»£p thÃªm. Sá»‘ tá»«: {content_words}")
            
            # LÃ m sáº¡ch ná»™i dung cuá»‘i cÃ¹ng - loáº¡i bá» dáº¥u "..." náº¿u cÃ³
            if content and content.endswith('...'):
                print("âš ï¸ PhÃ¡t hiá»‡n ná»™i dung káº¿t thÃºc báº±ng '...', Ä‘ang lÃ m sáº¡ch...")
                content = content.rstrip('...').strip()
                print(f"âœ… ÄÃ£ lÃ m sáº¡ch ná»™i dung: {content}")
            
            print(f"=== Káº¾T THÃšC Xá»¬ LÃ VIETNAMNET.VN - Káº¿t quáº£: {'ThÃ nh cÃ´ng' if content else 'Tháº¥t báº¡i'} ===")
            if content:
                print(f"Ná»™i dung cuá»‘i cÃ¹ng (Ä‘áº§y Ä‘á»§): {content}")
                print(f"Sá»‘ tá»«: {len(content.split())}")
                print(f"Äá»™ dÃ i kÃ½ tá»±: {len(content)}")
        
        elif 'nguoiduatin.vn' in url and not content:
            # TÃ¬m Ä‘oáº¡n vÄƒn chÃ­nh - thÆ°á»ng lÃ  Ä‘oáº¡n Ä‘áº§u tiÃªn sau tiÃªu Ä‘á»
            # Thá»­ nhiá»u cÃ¡ch tiáº¿p cáº­n khÃ¡c nhau
            content_selectors = [
                'div.detail p',
                'div.content p', 
                'article p',
                'div[class*="content"] p',
                'div[class*="article"] p',
                'div[class*="story"] p'
            ]
            
            for selector in content_selectors:
                paragraphs = soup.select(selector)
                if paragraphs:
                    for p in paragraphs:
                        text = p.get_text().strip()
                        # TÃ¬m Ä‘oáº¡n vÄƒn cÃ³ chá»©a tá»« khÃ³a chÃ­nh cá»§a bÃ i bÃ¡o
                        if (len(text) > 80 and 
                            ('biá»ƒu tÃ¬nh' in text.lower() or 'london' in text.lower() or 'tommy robinson' in text.lower()) and
                            not any(keyword in text.lower() for keyword in [
                                'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                                'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement',
                                'Ä‘Ã¡m Ä‘Ã´ng biá»ƒu tÃ¬nh táº­p trung'  # Loáº¡i bá» caption áº£nh cá»¥ thá»ƒ nÃ y
                            ])):
                            content = text
                            break
                    if content:
                        break
            
            # Náº¿u váº«n chÆ°a tÃ¬m tháº¥y, thá»­ tÃ¬m theo thá»© tá»± xuáº¥t hiá»‡n
            if not content:
                all_paragraphs = soup.find_all('p')
                for p in all_paragraphs:
                    text = p.get_text().strip()
                    if (len(text) > 80 and 
                        'biá»ƒu tÃ¬nh' in text.lower() and 
                        'london' in text.lower() and
                        'tommy robinson' in text.lower()):
                        content = text
                        break
        
        # Danh sÃ¡ch cÃ¡c selector Æ°u tiÃªn cho ná»™i dung chÃ­nh
        main_content_selectors = [
            '.article-content p',
            '.post-content p', 
            '.entry-content p',
            '.content p',
            'article p',
            '.article-body p',
            '[class*="content"] p',
            '.detail p',
            '.news-content p',
            '.story p'
        ]
        
        # TÃ¬m trong cÃ¡c container ná»™i dung chÃ­nh trÆ°á»›c (chá»‰ náº¿u chÆ°a cÃ³ content)
        if not content:
            for selector in main_content_selectors:
                content_elements = soup.select(selector)
                if content_elements:
                    for p in content_elements:
                        text = p.get_text().strip()
                        # Lá»c bá» cÃ¡c Ä‘oáº¡n vÄƒn khÃ´ng pháº£i ná»™i dung chÃ­nh
                        if (len(text) > 80 and 
                            not any(keyword in text.lower() for keyword in [
                                'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:', 
                                'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement',
                                'bÃ¬nh luáº­n', 'comment', 'chia sáº»', 'share',
                                'theo dÃµi', 'follow', 'Ä‘Äƒng kÃ½', 'subscribe'
                            ]) and
                            not text.startswith(('LiÃªn há»‡', 'GÃ³p Ã½', 'Quáº£ng cÃ¡o'))):
                            content = text
                            break
                    if content:
                        break
        
        # Náº¿u khÃ´ng tÃ¬m tháº¥y trong container chÃ­nh, tÃ¬m trong táº¥t cáº£ tháº» p
        if not content:
            all_paragraphs = soup.find_all('p')
            for p in all_paragraphs:
                text = p.get_text().strip()
                if (len(text) > 80 and 
                    not any(keyword in text.lower() for keyword in [
                        'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                        'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement', 
                        'bÃ¬nh luáº­n', 'comment', 'chia sáº»', 'share',
                        'theo dÃµi', 'follow', 'Ä‘Äƒng kÃ½', 'subscribe'
                    ]) and
                    not text.startswith(('LiÃªn há»‡', 'GÃ³p Ã½', 'Quáº£ng cÃ¡o'))):
                    content = text
                    break
        
        # Náº¿u ná»™i dung chÆ°a Ä‘á»§ 80 tá»«, láº¥y thÃªm Ä‘oáº¡n vÄƒn káº¿ tiáº¿p (cho trÆ°á»ng há»£p khÃ´ng cÃ³ meta description)
        if content:
            content_words = len(content.split())
            if content_words < 80:
                print(f"Ná»™i dung hiá»‡n táº¡i cÃ³ {content_words} tá»«, chÆ°a Ä‘á»§ 80 tá»«. Äang láº¥y thÃªm Ä‘oáº¡n vÄƒn káº¿ tiáº¿p...")
                
                # TÃ¬m Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
                all_paragraphs = soup.find_all('p')
                for i, p in enumerate(all_paragraphs):
                    text = p.get_text().strip()
                    if (len(text) > 50 and 
                        not any(keyword in text.lower() for keyword in [
                            'nguá»“n:', 'áº£nh:', 'photo:', 'image:', 'caption:',
                            'Ä‘Äƒng nháº­p', 'login', 'quáº£ng cÃ¡o', 'advertisement',
                            'bÃ¬nh luáº­n', 'comment', 'chia sáº»', 'share',
                            'theo dÃµi', 'follow', 'Ä‘Äƒng kÃ½', 'subscribe'
                        ]) and
                        not text.startswith(('LiÃªn há»‡', 'GÃ³p Ã½', 'Quáº£ng cÃ¡o'))):
                        
                        # Kiá»ƒm tra xem Ä‘oáº¡n nÃ y cÃ³ khÃ¡c vá»›i Ä‘oáº¡n Ä‘Ã£ láº¥y khÃ´ng
                        if text != content:
                            # Káº¿t há»£p Ä‘oáº¡n vÄƒn káº¿ tiáº¿p
                            combined_content = content + " " + text
                            combined_words = len(combined_content.split())
                            
                            print(f"ÄÃ£ káº¿t há»£p Ä‘oáº¡n vÄƒn káº¿ tiáº¿p. Tá»•ng tá»«: {combined_words}")
                            content = combined_content
                            
                            # Náº¿u Ä‘Ã£ Ä‘á»§ 80 tá»«, dá»«ng láº¡i
                            if combined_words >= 80:
                                break
        
        # Äáº¿m sá»‘ tá»«
        title_text = title or 'KhÃ´ng tÃ¬m tháº¥y tiÃªu Ä‘á»'
        content_text = content or 'KhÃ´ng tÃ¬m tháº¥y ná»™i dung'
        
        # Äáº¿m tá»« trong tiÃªu Ä‘á» vÃ  ná»™i dung
        title_words = len(title_text.split()) if title_text else 0
        content_words = len(content_text.split()) if content_text else 0
        total_words = title_words + content_words
        
        return {
            'title': title_text,
            'content': content_text,
            'word_count': {
                'title_words': title_words,
                'content_words': content_words,
                'total_words': total_words,
                'meets_minimum': total_words >= 80
            },
            'success': True
        }
        
    except requests.RequestException as e:
        error_str = str(e)
        print(f"âš ï¸ Requests error: {error_str}")
        
        # Náº¿u gáº·p SSL error, thá»­ dÃ¹ng Selenium
        if 'SSL' in error_str or 'CERTIFICATE' in error_str or 'ssl' in error_str.lower():
            print("ğŸ”„ SSL error detected, trying Selenium fallback...")
            try:
                selenium_result = extract_with_selenium(url)
                if selenium_result['success']:
                    print("âœ… Selenium fallback successful!")
                    return selenium_result
                else:
                    print("âŒ Selenium fallback failed, trying Gemini...")
                    # Náº¿u Selenium cÅ©ng fail, thá»­ Gemini
                    gemini_result = extract_with_gemini(url)
                    if gemini_result['success']:
                        print("âœ… Gemini fallback successful!")
                        return gemini_result
            except Exception as selenium_error:
                print(f"âŒ Selenium fallback error: {selenium_error}")
                try:
                    print("ğŸ”„ Trying Gemini as final fallback...")
                    gemini_result = extract_with_gemini(url)
                    if gemini_result['success']:
                        print("âœ… Gemini final fallback successful!")
                        return gemini_result
                except Exception as gemini_error:
                    print(f"âŒ All fallbacks failed. Gemini error: {gemini_error}")
        
        error_content = f'KhÃ´ng thá»ƒ truy cáº­p URL: {error_str}'
        return {
            'title': 'Lá»—i káº¿t ná»‘i',
            'content': error_content,
            'word_count': {
                'title_words': 0,
                'content_words': len(error_content.split()),
                'total_words': len(error_content.split()),
                'meets_minimum': False
            },
            'success': False
        }
    except Exception as e:
        error_content = f'Lá»—i khi xá»­ lÃ½ dá»¯ liá»‡u: {str(e)}'
        return {
            'title': 'Lá»—i xá»­ lÃ½',
            'content': error_content,
            'word_count': {
                'title_words': 0,
                'content_words': len(error_content.split()),
                'total_words': len(error_content.split()),
                'meets_minimum': False
            },
            'success': False
        }

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/extract', methods=['POST'])
def extract():
    # Há»— trá»£ cáº£ form data vÃ  JSON data
    if request.is_json:
        data = request.get_json()
        url = data.get('url', '').strip()
    else:
        url = request.form.get('url', '').strip()
    
    if not url:
        return jsonify({
            'title': 'Lá»—i',
            'content': 'Vui lÃ²ng nháº­p URL há»£p lá»‡',
            'success': False
        })
    
    # ThÃªm http:// náº¿u URL khÃ´ng cÃ³ protocol
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    result = extract_title_and_content(url)
    return jsonify(result)

@app.route('/batch_extract', methods=['POST'])
def batch_extract():
    urls_text = request.form.get('urls', '').strip()
    
    if not urls_text:
        return jsonify({
            'results': [],
            'error': 'Vui lÃ²ng nháº­p Ã­t nháº¥t má»™t URL'
        })
    
    # TÃ¡ch cÃ¡c URL tá»« text input
    urls = [url.strip() for url in urls_text.split('\n') if url.strip()]
    
    results = []
    for url in urls:
        # ThÃªm http:// náº¿u URL khÃ´ng cÃ³ protocol
        if not url.startswith(('http://', 'https://')):
            url = 'https://' + url
        
        result = extract_title_and_content(url)
        result['url'] = url
        results.append(result)
    
    return jsonify({'results': results})

if __name__ == '__main__':
    import os
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('FLASK_ENV') == 'development'
    app.run(debug=debug, host='0.0.0.0', port=port)
